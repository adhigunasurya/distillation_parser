{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we assume that we have the pycnn module in your path.\n",
    "# we also assume that LD_LIBRARY_PATH includes a pointer to where libcnn_shared.so is.\n",
    "from pycnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An LSTM/RNN overview:\n",
    "\n",
    "An (1-layer) RNN can be thought of as a sequence of cells, $h_1,...,h_k$, where $h_i$ indicates the time dimenstion. \n",
    "\n",
    "Each cell $h_i$ has an input $x_i$ and an output $r_i$. In addition to $x_i$, cell $h_i$ receives as input also $r_{i-1}$.\n",
    "\n",
    "In a deep (multi-layer) RNN, we don't have a sequence, but a grid. That is we have several layers of sequences:\n",
    "\n",
    "* $h_1^3,...,h_k^3$ \n",
    "* $h_1^2,...,h_k^2$ \n",
    "* $h_1^1,...h_k^1$, \n",
    "\n",
    "Let $r_i^j$ be the output of cell $h_i^j$. Then:\n",
    "\n",
    "The input to $h_i^1$ is $x_i$ and $r_{i-1}^1$.\n",
    "\n",
    "The input to $h_i^2$ is $r_i^1$ and $r_{i-1}^2$,\n",
    "and so on.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LSTM (RNN) Interface\n",
    "\n",
    "RNN / LSTM / GRU follow the same interface. We have a \"builder\" which is in charge of creating definining the parameters for the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "NUM_LAYERS=2\n",
    "INPUT_DIM=50\n",
    "HIDDEN_DIM=10\n",
    "builder = LSTMBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "# or:\n",
    "# builder = SimpleRNNBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we create the builder, it adds the internal RNN parameters to the `model`.\n",
    "We do not need to care about them, but they will be optimized together with the rest of the network's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = builder.initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = vecInput(INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1=s0.add_input(x1)\n",
    "y1 = s1.output()\n",
    "# here, we add x1 to the RNN, and the output we get from the top is y (a HIDEN_DIM-dim vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.npvalue().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2=s1.add_input(x1) # we can add another input\n",
    "y2=s2.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our LSTM/RNN was one layer deep, y2 would be equal to the hidden state. However, since it is 2 layers deep, y2 is only the hidden state (= output) of the last layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to want access to the all the hidden state (the output of both the first and the last layers), we could use the `.h()` method, which returns a list of expressions, one for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exprssion 54/0, exprssion 66/0)\n"
     ]
    }
   ],
   "source": [
    "print s2.h()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same interface that we saw until now for the LSTM, holds also for the Simple RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all layers: (exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "# create a simple rnn builder\n",
    "rnnbuilder=SimpleRNNBuilder(NUM_LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "\n",
    "# initialize a new graph, and a new sequence\n",
    "rs0 = rnnbuilder.initial_state()\n",
    "\n",
    "# add inputs\n",
    "rs1 = rs0.add_input(x1)\n",
    "ry1 = rs1.output()\n",
    "print \"all layers:\", s1.h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exprssion 28/0, exprssion 38/0, exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "print s1.s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, when calling `.add_input(x)` on an `RNNState` what happens is that the state creates a new RNN/LSTM column, passing it: \n",
    "1. the state of the current RNN column\n",
    "2. the input `x`\n",
    "\n",
    "The state is then returned, and we can call it's `output()` method to get the output `y`, which is the output at the top of the column. We can access the outputs of all the layers (not only the last one) using the `.h()` method of the state.\n",
    "\n",
    "**`.s()`** The internal state of the RNN may be more involved than just the outputs $h$. This is the case for the LSTM, that keeps an extra \"memory\" cell, that is used when calculating $h$, and which is also passed to the next column.  To access the entire hidden state, we use the `.s()` method. \n",
    "\n",
    "The output of `.s()` differs by the type of RNN being used. For the simple-RNN, it is the same as `.h()`. For the LSTM, it is more involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN h: (exprssion 74/0, exprssion 76/0)\n",
      "RNN s: (exprssion 74/0, exprssion 76/0)\n",
      "LSTM h: (exprssion 32/0, exprssion 42/0)\n",
      "LSTM s: (exprssion 28/0, exprssion 38/0, exprssion 32/0, exprssion 42/0)\n"
     ]
    }
   ],
   "source": [
    "rnn_h  = rs1.h()\n",
    "rnn_s  = rs1.s()\n",
    "print \"RNN h:\", rnn_h\n",
    "print \"RNN s:\", rnn_s\n",
    "\n",
    "\n",
    "lstm_h = s1.h()\n",
    "lstm_s = s1.s()\n",
    "print \"LSTM h:\", lstm_h\n",
    "print \"LSTM s:\", lstm_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the LSTM has two extra state expressions (one for each hidden layer) before the outputs h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra options in the RNN/LSTM interface\n",
    "\n",
    "**Stack LSTM** The RNN's are shaped as a stack: we can remove the top and continue from the previous state.\n",
    "This is done either by remembering the previous state and continuing it with a new `.add_input()`, or using\n",
    "we can access the previous state of a given state using the `.prev()` method of state.\n",
    "\n",
    "**Initializing a new sequence with a given state** When we call `builder.initial_state()`, we are assuming the state has random /0 initialization. If we want, we can specify a list of expressions that will serve as the initial state. The expected format is the same as the results of a call to `.final_s()`. TODO: this is not supported yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2=s1.add_input(x1)\n",
    "s3=s2.add_input(x1)\n",
    "s4=s3.add_input(x1)\n",
    "\n",
    "# let's continue s3 with a new input.\n",
    "s5=s3.add_input(x1)\n",
    "\n",
    "# we now have two different sequences:\n",
    "# s0,s1,s2,s3,s4\n",
    "# s0,s1,s2,s3,s5\n",
    "# the two sequences share parameters.\n",
    "\n",
    "assert(s5.prev() == s3)\n",
    "assert(s4.prev() == s3)\n",
    "\n",
    "s6=s3.prev().add_input(x1)\n",
    "# we now have an additional sequence:\n",
    "# s0,s1,s2,s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exprssion 184/0, exprssion 196/0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6.h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exprssion 180/0, exprssion 192/0, exprssion 184/0, exprssion 196/0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6.s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: memory efficient transduction\n",
    "The `RNNState` interface is convenient, and allows for incremental input construction.\n",
    "However, sometimes we know the sequence of inputs in advance, and care only about the sequence of\n",
    "output expressions. In this case, we can use the `add_inputs(xs)` method, where `xs` is a list of Expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exprssion 248/0, exprssion 254/0, exprssion 260/0] [(exprssion 246/0, exprssion 248/0), (exprssion 251/0, exprssion 254/0), (exprssion 257/0, exprssion 260/0)]\n"
     ]
    }
   ],
   "source": [
    "state = rnnbuilder.initial_state()\n",
    "xs = [x1,x1,x1]\n",
    "states = state.add_inputs(xs)\n",
    "outputs = [s.output() for s in states]\n",
    "hs =      [s.h() for s in states]\n",
    "print outputs, hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is convenient.\n",
    "\n",
    "What if we do not care about `.s()` and `.h()`, and do not need to access the previous vectors? In such cases\n",
    "we can use the `transduce(xs)` method instead of `add_inputs(xs)`.\n",
    "`transduce` takes in a sequence of `Expression`s, and returns a sequence of `Expression`s.\n",
    "As a consequence of not returning `RNNState`s, `trnasduce` is much more memory efficient than `add_inputs` or a series of calls to `add_input`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exprssion 280/0, exprssion 286/0, exprssion 292/0]\n"
     ]
    }
   ],
   "source": [
    "state = rnnbuilder.initial_state()\n",
    "xs = [x1,x1,x1]\n",
    "outputs = state.transduce(xs)\n",
    "print outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Charecter-level LSTM\n",
    "\n",
    "Now that we know the basics of RNNs, let's build a character-level LSTM language-model.\n",
    "We have a sequence LSTM that, at each step, gets as input a character, and needs to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "import sys\n",
    "\n",
    "LAYERS = 2\n",
    "INPUT_DIM = 50 \n",
    "HIDDEN_DIM = 50  \n",
    "\n",
    "characters = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "characters.append(\"<EOS>\")\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "\n",
    "srnn = SimpleRNNBuilder(LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "lstm = LSTMBuilder(LAYERS, INPUT_DIM, HIDDEN_DIM, model)\n",
    "\n",
    "model.add_lookup_parameters(\"lookup\", (VOCAB_SIZE, INPUT_DIM))\n",
    "model.add_parameters(\"R\", (VOCAB_SIZE, HIDDEN_DIM))\n",
    "model.add_parameters(\"bias\", (VOCAB_SIZE))\n",
    "\n",
    "# return compute loss of RNN for one sentence\n",
    "def do_one_sentence(rnn, sentence):\n",
    "    # setup the sentence\n",
    "    renew_cg()\n",
    "    s0 = rnn.initial_state()\n",
    "    \n",
    "    \n",
    "    R = parameter(model[\"R\"])\n",
    "    bias = parameter(model[\"bias\"])\n",
    "    lookup = model[\"lookup\"]\n",
    "    sentence = [\"<EOS>\"] + list(sentence) + [\"<EOS>\"]\n",
    "    sentence = [char2int[c] for c in sentence]\n",
    "    s = s0\n",
    "    loss = []\n",
    "    for char,next_char in zip(sentence,sentence[1:]):\n",
    "        s = s.add_input(lookup[char])\n",
    "        probs = softmax(R*s.output() + bias)\n",
    "        loss.append( -log(pick(probs,next_char)) )\n",
    "    loss = esum(loss)\n",
    "    return loss\n",
    " \n",
    "\n",
    "# generate from model:\n",
    "def generate(rnn):\n",
    "    def sample(probs):\n",
    "        rnd = random.random()\n",
    "        for i,p in enumerate(probs):\n",
    "            rnd -= p\n",
    "            if rnd <= 0: break\n",
    "        return i\n",
    "    \n",
    "    # setup the sentence\n",
    "    renew_cg()\n",
    "    s0 = rnn.initial_state()\n",
    "    \n",
    "    R = parameter(model[\"R\"])\n",
    "    bias = parameter(model[\"bias\"])\n",
    "    lookup = model[\"lookup\"]\n",
    "    \n",
    "    s = s0.add_input(lookup[char2int[\"<EOS>\"]])\n",
    "    out=[]\n",
    "    while True:\n",
    "        probs = softmax(R*s.output() + bias)\n",
    "        probs = probs.vec_value()\n",
    "        next_char = sample(probs)\n",
    "        out.append(int2char[next_char])\n",
    "        if out[-1] == \"<EOS>\": break\n",
    "        s = s.add_input(lookup[next_char])\n",
    "    return \"\".join(out[:-1]) # strip the <EOS>\n",
    "        \n",
    "\n",
    "# train, and generate every 5 samples\n",
    "def train(rnn, sentence):\n",
    "    trainer = SimpleSGDTrainer(model)\n",
    "    for i in xrange(200):\n",
    "        loss = do_one_sentence(rnn, sentence)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "        if i % 5 == 0: \n",
    "            print loss_value,\n",
    "            print generate(rnn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "1. We pass the same rnn-builder to `do_one_sentence` over and over again.\n",
    "We must re-use the same rnn-builder, as this is where the shared parameters are kept.\n",
    "2. We `renew_cg()` before each sentence -- because we want to have a new graph (new network) for this sentence.\n",
    "The parameters will be shared through the model and the shared rnn-builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.033477783 uloocopmczrrjnai funpgrh gn\n",
      "91.8539962769 nonfg rujw  ogil rz bfagqome  doouqarbayv  nkfkq fa  ryeafeoi\n",
      "54.739528656  fie qmek tgs   uzv\n",
      "30.164937973 z ouwu  ol ruiheb \n",
      "10.7598457336 a fuic\n",
      "3.2049407959 a quico bgow   ary dufox oumped over the lazy dog\n",
      "1.03240394592 a quick brown fox jumped over the lazy dog\n",
      "0.650553286076 a quick brown fox jumped over the lazy dog\n",
      "0.47541359067 a qukck brown fox jumped over the lazy dog\n",
      "0.374430119991 a quick brown fox jumped over the lazy dog\n",
      "0.308728694916 a quick brown fox jumped over the lazy dog\n",
      "0.262536674738 a quick brown fox jumped over the lazy dog\n",
      "0.22830298543 a quick brown fox jumped over the lazy dog\n",
      "0.201896265149 a quick brown fox jumped over the lazy dog\n",
      "0.180914476514 a quick brown fox jumped over the lazy dog\n",
      "0.1638764292 a quick brown fox jumped over the lazy dog\n",
      "0.149730876088 a quick brown fox jumped over the lazy dog\n",
      "0.137800350785 a quick brown fox jumped over the lazy dog\n",
      "0.127627104521 a quick brown fox jumped over the lazy dog\n",
      "0.118834555149 a quick brown fox jumped over the lazy dog\n",
      "0.111203595996 a quick brown fox jumped over the lazy dog\n",
      "0.104423552752 a quick brown fox jumped over the lazy dog\n",
      "0.0984442383051 a quick brown fox jumped over the lazy dog\n",
      "0.0930855795741 a quick brown fox jumped over the lazy dog\n",
      "0.0882897824049 a quick brown fox jumped over the lazy dog\n",
      "0.0839573442936 a quick brown fox jumped over the lazy dog\n",
      "0.0800611972809 a quick brown fox jumped over the lazy dog\n",
      "0.0764751881361 a quick brown fox jumped over the lazy dog\n",
      "0.0732067674398 a quick brown fox jumped over the lazy dog\n",
      "0.0701641961932 a quick brown fox jumped over the lazy dog\n",
      "0.0673855319619 a quick brown fox jumped over the lazy dog\n",
      "0.0648249685764 a quick brown fox jumped over the lazy dog\n",
      "0.0623983256519 a quick brown fox jumped over the lazy dog\n",
      "0.060231667012 a quick brown fox jumped over the lazy dog\n",
      "0.0581797286868 a quick brown fox jumped over the lazy dog\n",
      "0.0562158599496 a quick brown fox jumped over the lazy dog\n",
      "0.0544277988374 a quick brown fox jumped over the lazy dog\n",
      "0.0527582615614 a quick brown fox jumped over the lazy dog\n",
      "0.0511232204735 a quick brown fox jumped over the lazy dog\n",
      "0.0496219098568 a quick brown fox jumped over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "sentence = \"a quick brown fox jumped over the lazy dog\"\n",
    "train(srnn, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.304412842 prmnuxlwid  d ux udn  o axez da lxojhfu dp z\n",
      "129.910614014 skedaeip m vn eji ru w \n",
      "124.140289307 y ogzi d  uj ch oaoag  p ivo c ft ghd rl od vqo p rm pottx e  ehrto odou pky ojmoxurootff r mhe u\n",
      "111.025337219 r ktue wkxu\n",
      "98.0487518311 ckx roxy oinad juee reee yrhs wddt cr hej qvpn to ah jplfee h cejte yh\n",
      "81.2529830933 d roqo cbn uotx uojp dncfooar gdpbooguy \n",
      "68.0369262695  lu gu zupn oxe ex ghd fhx jzr dom eahpfm\n",
      "54.3006706238 jc cg uupkbkoogvwo no\n",
      "42.3075561523  uqci jufk def rw ummtl uik born uuuii bkrn dokn rfow lup\n",
      "31.4120750427 br dtojej\n",
      "22.4915180206 aa quick brown oox fumpfeer over the ol\n",
      "15.6982011795  qxic bbrwn fox jumpjoer ooe laz doe\n",
      "10.5527915955 d gbrown fox jumped overat\n",
      "6.46443843842 l qumpd dog\n",
      "3.84945011139 a quick brown fox ee lzt jmmped over the lazy dog\n",
      "2.08847999573 a quick brown fox jumped over the lazy dog\n",
      "1.49571335316 a quick brown fox jumped over the lazy dog\n",
      "1.15657103062 a quicb brown fox jumped over the lazy dog\n",
      "0.938805937767 a quick brown fox jumped over tan fover the lazy dog\n",
      "0.788115262985 a quick brown fox jumped over ohe lazy dog\n",
      "0.678014576435 a quick brown fox jumped over the lazy dog\n",
      "0.594275057316 a quick brown fox jumped over the lazy dog\n",
      "0.52849572897 a quicqk brown fox jumped over the lazy dog\n",
      "0.4755628407 a quick brown fox jumped over the lazy dog\n",
      "0.432055711746 x quick brown fox jumped over the lazy dog\n",
      "0.39562445879 a quick broon fox jumped over the lazy dog\n",
      "0.364839941263 a quick brown fox jumped over the lazed over the lazy dog\n",
      "0.338363438845 a quick brown fox jumped over the lazy dog\n",
      "0.315368592739 a quick brown fox jumped over the lazy dog\n",
      "0.295288294554 a quik brown fox jumped over the lazy dog\n",
      "0.277546137571 a quick brown fox jumped over the lazy dog\n",
      "0.261784315109 a quick brown fox jumped over the lazy dog\n",
      "0.2476875633 a quick brown fox jumpeef over the lazy dog\n",
      "0.234950631857 a quick brown fox jumped over the lazy dog\n",
      "0.223440438509 a quick brown fox jumped over the lazy dog\n",
      "0.21306720376 a quick buown fox jumped over the lazy dog\n",
      "0.2035497576 a quick brown fox jumped over the lazed overr the lazy dog\n",
      "0.194814369082 a kuickk qown fox jumped over the lazy dog\n",
      "0.18677970767 a quick brown fox jumped over the lazy dog\n",
      "0.179387688637 aa quick brown fox jumped over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "sentence = \"a quick brown fox jumped over the lazy dog\"\n",
    "train(lstm, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seem to learn the sentence quite well.\n",
    "\n",
    "Somewhat surprisingly, the Simple-RNN model learn quicker than the LSTM!\n",
    "\n",
    "How can that be?\n",
    "\n",
    "The answer is that we are cheating a bit. The sentence we are trying to learn\n",
    "has each letter-bigram exactly once. This means a simple trigram model can memorize\n",
    "it very well.\n",
    "\n",
    "Try it out with more complex sequences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.059265137 a quick brown fox jumped over the lazy dog\n",
      "97.8145599365 a quick brown fox jumped over the lazy dog\n",
      "52.8635063171 a quickxbrown fox jumped over therntz\n",
      "24.4791564941 a quick brown fox jumped over thirn vr the n pritu\n",
      "4.01108551025 thece prejzels are muking mre n the laz oakd gretzels are mupte\n",
      "1.92300200462 these pretzels are making me thirsty\n",
      "0.39481985569 these pretzels are making me thirsty\n",
      "0.135318264365 these pretzels are making me thirsty\n",
      "0.101885713637 these pretzels are making me thirsty\n",
      "0.0829276740551 these pretzels are making me thirsty\n",
      "0.0703410431743 these pretzels are making me thirsty\n",
      "0.0612589642406 these pretzels are making me thirsty\n",
      "0.054374050349 these pretzels are making me thirsty\n",
      "0.0489393435419 these pretzels are making me thirsty\n",
      "0.0445105880499 these pretzels are making me thirsty\n",
      "0.0409039668739 these pretzels are making me thirsty\n",
      "0.0377906225622 these pretzels are making me thirsty\n",
      "0.0351626649499 these pretzels are making me thirsty\n",
      "0.0328748859465 these pretzels are making me thirsty\n",
      "0.0309081021696 these pretzels are making me thirsty\n",
      "0.0291361920536 these pretzels are making me thirsty\n",
      "0.0275705922395 these pretzels are making me thirsty\n",
      "0.0261883735657 these pretzels are making me thirsty\n",
      "0.0249245800078 these pretzels are making me thirsty\n",
      "0.0237868223339 these pretzels are making me thirsty\n",
      "0.0227445568889 these pretzels are making me thirsty\n",
      "0.0217939633876 these pretzels are making me thirsty\n",
      "0.020915934816 these pretzels are making me thirsty\n",
      "0.0200990028679 these pretzels are making me thirsty\n",
      "0.0193889811635 these pretzels are making me thirsty\n",
      "0.0187018848956 these pretzels are making me thirsty\n",
      "0.0180453378707 these pretzels are making me thirsty\n",
      "0.017415529117 these pretzels are making me thirsty\n",
      "0.016888782382 these pretzels are making me thirsty\n",
      "0.0163544174284 these pretzels are making me thirsty\n",
      "0.0158963911235 these pretzels are making me thirsty\n",
      "0.0153925828636 these pretzels are making me thirsty\n",
      "0.0149803832173 these pretzels are making me thirsty\n",
      "0.0145872598514 these pretzels are making me thirsty\n",
      "0.0141636235639 these pretzels are making me thirsty\n"
     ]
    }
   ],
   "source": [
    "train(srnn, \"these pretzels are making me thirsty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
